{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Amazon SageMaker Autopilot is an automated machine learning (commonly referred to as AutoML) solution for tabular datasets. You can use SageMaker Autopilot in different ways: on autopilot (hence the name) or with human guidance, without code through SageMaker Studio, or using the AWS SDKs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 781 ms, sys: 96.9 ms, total: 878 ms\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import get_execution_role\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "bucket='sainsbury-workshop-autopilot' # put your s3 bucket name here, and create s3 bucket\n",
    "prefix = 'sagemaker/DEMO-xgboost-autopilot'\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize to your bucket where you have stored the data\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "items = pd.read_csv('data/items.csv')\n",
    "holidays_events = pd.read_csv('data/holidays_events.csv')\n",
    "oil = pd.read_csv('data/oil.csv')\n",
    "stores = pd.read_csv('data/stores.csv')\n",
    "transactions = pd.read_csv('data/transactions.csv')\n",
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     type\n",
       "0  2012-03-02  Holiday\n",
       "1  2012-04-01  Holiday\n",
       "2  2012-04-12  Holiday\n",
       "3  2012-04-14  Holiday\n",
       "4  2012-04-21  Holiday"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "holidays_events = holidays_events[['date','type']]\n",
    "holidays_events.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62748520, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.sample(frac=0.5, replace=False, random_state=1)\n",
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(df_train, stores, on= \"store_nbr\")\n",
    "train = pd.merge(train, items, on= \"item_nbr\")\n",
    "train = pd.merge(train, holidays_events, on=\"date\")\n",
    "train = pd.merge(train, oil, on =\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train.unit_sales<0),'unit_sales'] = 1 \n",
    "rolling_mean_5 = train.groupby(['item_nbr','store_nbr'])['unit_sales'].apply(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
    "rolling_mean_family_5 = train.groupby(['family','store_nbr'])['unit_sales'].apply(lambda x: x.shift().rolling(5, min_periods=1).mean())\n",
    "rolling_mean_30 = train.groupby(['item_nbr','store_nbr'])['unit_sales'].apply(lambda x: x.shift().rolling(30, min_periods=1).mean())\n",
    "rolling_mean_family_30 = train.groupby(['family','store_nbr'])['unit_sales'].apply(lambda x: x.shift().rolling(30, min_periods=1).mean())\n",
    "train['unit_rolling_mean_5'] = rolling_mean_5\n",
    "train['unit_rolling_mean_family_5'] = rolling_mean_family_5\n",
    "train['unit_rolling_mean_30'] = rolling_mean_30\n",
    "train['unit_rolling_mean_family_30'] = rolling_mean_family_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = pd.DatetimeIndex(train['date']).month\n",
    "train['dow'] = pd.DatetimeIndex(train['date']).dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_x</th>\n",
       "      <th>cluster</th>\n",
       "      <th>...</th>\n",
       "      <th>unit_rolling_mean_family_5</th>\n",
       "      <th>unit_rolling_mean_30</th>\n",
       "      <th>unit_rolling_mean_family_30</th>\n",
       "      <th>month</th>\n",
       "      <th>dow</th>\n",
       "      <th>unit_log_sales</th>\n",
       "      <th>unit_log_rolling_mean_5</th>\n",
       "      <th>unit_log_rolling_mean_family_5</th>\n",
       "      <th>unit_log_rolling_mean_30</th>\n",
       "      <th>unit_log_rolling_mean_family_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7599991</th>\n",
       "      <td>446</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>911429</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.028148</td>\n",
       "      <td>0.875469</td>\n",
       "      <td>1.829911</td>\n",
       "      <td>1.299283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599992</th>\n",
       "      <td>296</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>638327</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.280934</td>\n",
       "      <td>0.847298</td>\n",
       "      <td>1.352393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599993</th>\n",
       "      <td>544</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>1071949</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.526056</td>\n",
       "      <td>1.481605</td>\n",
       "      <td>1.866661</td>\n",
       "      <td>2.285778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599994</th>\n",
       "      <td>185</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>420720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.163151</td>\n",
       "      <td>1.568616</td>\n",
       "      <td>1.317301</td>\n",
       "      <td>1.763589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599995</th>\n",
       "      <td>149</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>363868</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.648659</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.722767</td>\n",
       "      <td>1.360977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        date  store_nbr  item_nbr  unit_sales onpromotion  \\\n",
       "7599991  446  2013-01-01         25    911429         7.0         NaN   \n",
       "7599992  296  2013-01-01         25    638327         2.0         NaN   \n",
       "7599993  544  2013-01-01         25   1071949         6.0         NaN   \n",
       "7599994  185  2013-01-01         25    420720         2.0         NaN   \n",
       "7599995  149  2013-01-01         25    363868         2.0         NaN   \n",
       "\n",
       "            city        state type_x  cluster  ... unit_rolling_mean_family_5  \\\n",
       "7599991  Salinas  Santa Elena      D        1  ...                        1.4   \n",
       "7599992  Salinas  Santa Elena      D        1  ...                        2.6   \n",
       "7599993  Salinas  Santa Elena      D        1  ...                        3.4   \n",
       "7599994  Salinas  Santa Elena      D        1  ...                        3.8   \n",
       "7599995  Salinas  Santa Elena      D        1  ...                        2.8   \n",
       "\n",
       "         unit_rolling_mean_30  unit_rolling_mean_family_30 month  dow  \\\n",
       "7599991              5.233333                     2.666667     1    1   \n",
       "7599992              1.333333                     2.866667     1    1   \n",
       "7599993              5.466667                     8.833333     1    1   \n",
       "7599994              2.733333                     4.833333     1    1   \n",
       "7599995              4.600000                     2.900000     1    1   \n",
       "\n",
       "         unit_log_sales  unit_log_rolling_mean_5  \\\n",
       "7599991        2.079442                 2.028148   \n",
       "7599992        1.098612                 0.847298   \n",
       "7599993        1.945910                 1.526056   \n",
       "7599994        1.098612                 1.163151   \n",
       "7599995        1.098612                 1.648659   \n",
       "\n",
       "         unit_log_rolling_mean_family_5  unit_log_rolling_mean_30  \\\n",
       "7599991                        0.875469                  1.829911   \n",
       "7599992                        1.280934                  0.847298   \n",
       "7599993                        1.481605                  1.866661   \n",
       "7599994                        1.568616                  1.317301   \n",
       "7599995                        1.335001                  1.722767   \n",
       "\n",
       "         unit_log_rolling_mean_family_30  \n",
       "7599991                         1.299283  \n",
       "7599992                         1.352393  \n",
       "7599993                         2.285778  \n",
       "7599994                         1.763589  \n",
       "7599995                         1.360977  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['unit_log_sales'] =  train['unit_sales'].apply(pd.np.log1p) \n",
    "train['unit_log_rolling_mean_5'] =  train['unit_rolling_mean_5'].apply(pd.np.log1p) \n",
    "train['unit_log_rolling_mean_family_5'] =  train['unit_rolling_mean_family_5'].apply(pd.np.log1p) \n",
    "train['unit_log_rolling_mean_30'] =  train['unit_rolling_mean_30'].apply(pd.np.log1p) \n",
    "train['unit_log_rolling_mean_family_30'] =  train['unit_rolling_mean_family_30'].apply(pd.np.log1p) \n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_x</th>\n",
       "      <th>cluster</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>type_y</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>month</th>\n",
       "      <th>dow</th>\n",
       "      <th>unit_log_sales</th>\n",
       "      <th>unit_log_rolling_mean_5</th>\n",
       "      <th>unit_log_rolling_mean_family_5</th>\n",
       "      <th>unit_log_rolling_mean_30</th>\n",
       "      <th>unit_log_rolling_mean_family_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Machala</td>\n",
       "      <td>El Oro</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3034</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>99.69</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3034</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>99.69</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>Azuay</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3034</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>99.69</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Latacunga</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>C</td>\n",
       "      <td>15</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3034</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>99.69</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Guayaquil</td>\n",
       "      <td>Guayas</td>\n",
       "      <td>E</td>\n",
       "      <td>10</td>\n",
       "      <td>CLEANING</td>\n",
       "      <td>3034</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>99.69</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  onpromotion       city      state type_x cluster    family class perishable  \\\n",
       "0       False    Machala     El Oro      D       4  CLEANING  3034          0   \n",
       "1       False      Quito  Pichincha      A       5  CLEANING  3034          0   \n",
       "2       False     Cuenca      Azuay      D       2  CLEANING  3034          0   \n",
       "3       False  Latacunga   Cotopaxi      C      15  CLEANING  3034          0   \n",
       "4       False  Guayaquil     Guayas      E      10  CLEANING  3034          0   \n",
       "\n",
       "    type_y  dcoilwtico month dow  unit_log_sales  unit_log_rolling_mean_5  \\\n",
       "0  Holiday       99.69     5   3        1.098612                      NaN   \n",
       "1  Holiday       99.69     5   3        1.098612                      NaN   \n",
       "2  Holiday       99.69     5   3        1.098612                      NaN   \n",
       "3  Holiday       99.69     5   3        0.693147                      NaN   \n",
       "4  Holiday       99.69     5   3        2.708050                      NaN   \n",
       "\n",
       "   unit_log_rolling_mean_family_5  unit_log_rolling_mean_30  \\\n",
       "0                             NaN                       NaN   \n",
       "1                             NaN                       NaN   \n",
       "2                             NaN                       NaN   \n",
       "3                             NaN                       NaN   \n",
       "4                             NaN                       NaN   \n",
       "\n",
       "   unit_log_rolling_mean_family_30  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['date','id','store_nbr', 'item_nbr','unit_sales','unit_rolling_mean_5','unit_rolling_mean_family_5','unit_rolling_mean_30','unit_rolling_mean_family_30'], axis=1)\n",
    "for col in ['cluster', 'class', 'perishable','month','dow']:\n",
    "    train[col] = train[col].astype('category')\n",
    "type(train['cluster'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = np.split(train.sample(frac=1, random_state=1729), [int(0.8 * len(train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        onpromotion       city       state type_x cluster     family class  \\\n",
      "4166185       False  Guayaquil      Guayas      D       1  BEVERAGES  1114   \n",
      "7331994         NaN     Ambato  Tungurahua      A      14  GROCERY I  1072   \n",
      "1141056       False      Quito   Pichincha      C      12   CLEANING  3032   \n",
      "2022293       False      Quito   Pichincha      D       8  GROCERY I  1040   \n",
      "3978783       False  Guayaquil      Guayas      A      17   CLEANING  3044   \n",
      "\n",
      "        perishable    type_y  dcoilwtico month dow  unit_log_sales  \\\n",
      "4166185          0   Holiday       47.83     5   4        1.098612   \n",
      "7331994          0   Holiday       90.74     5   2        2.639057   \n",
      "1141056          0     Event       43.65     5   1        1.609438   \n",
      "2022293          0     Event      104.06     7   1        2.833213   \n",
      "3978783          0  Transfer       49.58     5   4        1.609438   \n",
      "\n",
      "         unit_log_rolling_mean_5  unit_log_rolling_mean_family_5  \\\n",
      "4166185                 1.609438                        2.028148   \n",
      "7331994                 2.104134                        2.468100   \n",
      "1141056                 1.648659                        1.481605   \n",
      "2022293                 2.451005                        1.280934   \n",
      "3978783                 1.568616                        2.517696   \n",
      "\n",
      "         unit_log_rolling_mean_30  unit_log_rolling_mean_family_30  \n",
      "4166185                  1.717651                         1.907070  \n",
      "7331994                  2.465271                         2.525729  \n",
      "1141056                  1.540445                         2.197225  \n",
      "2022293                  2.211613                         1.987874  \n",
      "3978783                  1.752094                         2.289162  \n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_data.csv';\n",
    "train_data.to_csv(train_file, index=False, header=True)\n",
    "test_file = 'test_data.csv';\n",
    "test_data_no_target = test_data.drop(columns=['unit_log_sales'])\n",
    "test_data_no_target.to_csv(test_file, index=False, header=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train_data.csv')).upload_file('train_data.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test_data.csv')).upload_file('test_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the SageMaker Autopilot Job<a name=\"Settingup\"></a>\n",
    "\n",
    "After uploading the dataset to Amazon S3, you can invoke Autopilot to find the best ML pipeline to train a model on this dataset. \n",
    "\n",
    "The required inputs for invoking a Autopilot job are:\n",
    "* Amazon S3 location for input dataset and for all output artifacts\n",
    "* Name of the column of the dataset you want to predict (`AG` in this case) \n",
    "* An IAM role\n",
    "\n",
    "Currently Autopilot supports only tabular datasets in CSV format. Either all files should have a header row, or the first file of the dataset, when sorted in alphabetical/lexical order, is expected to have a header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_config = [{\n",
    "      'DataSource': {\n",
    "        'S3DataSource': {\n",
    "          'S3DataType': 'S3Prefix',\n",
    "          'S3Uri': 's3://{}/{}/train'.format(bucket,prefix)\n",
    "        }\n",
    "      },\n",
    "      'TargetAttributeName': 'unit_log_sales'\n",
    "    }\n",
    "  ]\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': 's3://{}/{}/output'.format(bucket,prefix)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLJobName: automl-kaggle-25-20-30-03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AutoMLJobArn': 'arn:aws:sagemaker:us-east-1:208480242416:automl-job/automl-kaggle-25-20-30-03',\n",
       " 'ResponseMetadata': {'RequestId': '7dde419a-767e-4a30-bed8-cc78b5650ace',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '7dde419a-767e-4a30-bed8-cc78b5650ace',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '96',\n",
       "   'date': 'Tue, 25 Feb 2020 20:30:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "timestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "auto_ml_job_name = 'automl-kaggle-' + timestamp_suffix\n",
    "print('AutoMLJobName: ' + auto_ml_job_name)\n",
    "\n",
    "sm.create_auto_ml_job(AutoMLJobName=auto_ml_job_name,\n",
    "                      InputDataConfig=input_data_config,\n",
    "                      OutputDataConfig=output_data_config,\n",
    "                      RoleArn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking SageMaker Autopilot job progress<a name=\"Tracking\"></a>\n",
    "SageMaker Autopilot job consists of the following high-level steps : \n",
    "* Analyzing Data, where the dataset is analyzed and Autopilot comes up with a list of ML pipelines that should be tried out on the dataset. The dataset is also split into train and validation sets.\n",
    "* Feature Engineering, where Autopilot performs feature transformation on individual features of the dataset as well as at an aggregate level.\n",
    "* Model Tuning, where the top performing pipeline is selected along with the optimal hyperparameters for the training algorithm (the last stage of the pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus - Secondary Status\n",
      "------------------------------\n",
      "Completed - MaxCandidatesReached\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus - Secondary Status')\n",
    "print('------------------------------')\n",
    "\n",
    "\n",
    "describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "    print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CandidateName': 'tuning-job-1-16dfc46c15f94841b4-202-f414791f', 'FinalAutoMLJobObjectiveMetric': {'MetricName': 'validation:mse', 'Value': 0.29326900839805603}, 'ObjectiveStatus': 'Succeeded', 'CandidateSteps': [{'CandidateStepType': 'AWS::SageMaker::ProcessingJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:208480242416:processing-job/db-1-a11387f1ba86405ea94da87383456cf0ffa0a0ae17924decaf375e0a24', 'CandidateStepName': 'db-1-a11387f1ba86405ea94da87383456cf0ffa0a0ae17924decaf375e0a24'}, {'CandidateStepType': 'AWS::SageMaker::TrainingJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:208480242416:training-job/automl-kag-dpp1-1-57da327e049e4d95ac88003f24fa897d899e2caf77a44', 'CandidateStepName': 'automl-kag-dpp1-1-57da327e049e4d95ac88003f24fa897d899e2caf77a44'}, {'CandidateStepType': 'AWS::SageMaker::TransformJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:208480242416:transform-job/automl-kag-dpp1-rpb-1-429ae0423a494abc886765f1859f917ad716d099e', 'CandidateStepName': 'automl-kag-dpp1-rpb-1-429ae0423a494abc886765f1859f917ad716d099e'}, {'CandidateStepType': 'AWS::SageMaker::TrainingJob', 'CandidateStepArn': 'arn:aws:sagemaker:us-east-1:208480242416:training-job/tuning-job-1-16dfc46c15f94841b4-202-f414791f', 'CandidateStepName': 'tuning-job-1-16dfc46c15f94841b4-202-f414791f'}], 'CandidateStatus': 'Completed', 'InferenceContainers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-sklearn-automl:0.1.0-cpu-py3', 'ModelDataUrl': 's3://sainsbury-workshop-autopilot/sagemaker/DEMO-xgboost-autopilot/output/automl-kaggle-25-20-30-03/data-processor-models/automl-kag-dpp1-1-57da327e049e4d95ac88003f24fa897d899e2caf77a44/output/model.tar.gz', 'Environment': {'AUTOML_SPARSE_ENCODE_RECORDIO_PROTOBUF': '1', 'AUTOML_TRANSFORM_MODE': 'feature-transform', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'application/x-recordio-protobuf', 'SAGEMAKER_PROGRAM': 'sagemaker_serve', 'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/sagemaker_serve.py'}}, {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:0.90-1-cpu-py3', 'ModelDataUrl': 's3://sainsbury-workshop-autopilot/sagemaker/DEMO-xgboost-autopilot/output/automl-kaggle-25-20-30-03/tuning/automl-kag-dpp1-xgb/tuning-job-1-16dfc46c15f94841b4-202-f414791f/output/model.tar.gz', 'Environment': {'MAX_CONTENT_LENGTH': '20971520', 'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT': 'text/csv'}}], 'CreationTime': datetime.datetime(2020, 2, 26, 9, 20, 20, 967000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2020, 2, 26, 9, 20, 20, 967000, tzinfo=tzlocal())}\n",
      "\n",
      "\n",
      "CandidateName: tuning-job-1-16dfc46c15f94841b4-202-f414791f\n",
      "FinalAutoMLJobObjectiveMetricName: validation:mse\n",
      "FinalAutoMLJobObjectiveMetricValue: 0.29326900839805603\n"
     ]
    }
   ],
   "source": [
    "best_candidate = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "print(best_candidate)\n",
    "print('\\n')\n",
    "print(\"CandidateName: \" + best_candidate_name)\n",
    "print(\"FinalAutoMLJobObjectiveMetricName: \" + best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "print(\"FinalAutoMLJobObjectiveMetricValue: \" + str(best_candidate['FinalAutoMLJobObjectiveMetric']['Value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform batch inference using the best candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ARN corresponding to the best candidate is : arn:aws:sagemaker:us-east-1:208480242416:model/automl-kaggle-regression-model-25-20-30-03\n"
     ]
    }
   ],
   "source": [
    "model_name = 'automl-kaggle-regression-model-' + timestamp_suffix\n",
    "\n",
    "model = sm.create_model(Containers=best_candidate['InferenceContainers'],\n",
    "                            ModelName=model_name,\n",
    "                            ExecutionRoleArn=role)\n",
    "\n",
    "print('Model ARN corresponding to the best candidate is : {}'.format(model['ModelArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use batch inference by using Amazon SageMaker batch transform. The same model can also be deployed to perform online inference using Amazon SageMaker hosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TransformJobArn': 'arn:aws:sagemaker:us-east-1:208480242416:transform-job/automl-kaggle-regression-transform-25-20-30-03',\n",
       " 'ResponseMetadata': {'RequestId': '31d06955-16c2-4a43-bcdf-adf25703a04a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '31d06955-16c2-4a43-bcdf-adf25703a04a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '123',\n",
       "   'date': 'Wed, 26 Feb 2020 09:55:58 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_job_name = 'automl-kaggle-regression-transform-' + timestamp_suffix\n",
    "\n",
    "transform_input = {\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': 's3://{}/{}/test/test_data.csv'.format(bucket,prefix)\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'text/csv',\n",
    "        'CompressionType': 'None',\n",
    "        'SplitType': 'Line'\n",
    "    }\n",
    "\n",
    "transform_output = {\n",
    "        'S3OutputPath': 's3://{}/{}/inference-results'.format(bucket,prefix),\n",
    "    }\n",
    "\n",
    "transform_resources = {\n",
    "        'InstanceType': 'ml.m5.4xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    "\n",
    "sm.create_transform_job(TransformJobName = transform_job_name,\n",
    "                        ModelName = model_name,\n",
    "                        TransformInput = transform_input,\n",
    "                        TransformOutput = transform_output,\n",
    "                        TransformResources = transform_resources\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobStatus\n",
      "----------\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n"
     ]
    }
   ],
   "source": [
    "print ('JobStatus')\n",
    "print('----------')\n",
    "\n",
    "\n",
    "describe_response = sm.describe_transform_job(TransformJobName = transform_job_name)\n",
    "job_run_status = describe_response['TransformJobStatus']\n",
    "print (job_run_status)\n",
    "\n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_transform_job(TransformJobName = transform_job_name)\n",
    "    job_run_status = describe_response['TransformJobStatus']\n",
    "    print (job_run_status)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Generation Notebook\n",
    "\n",
    "Sagemaker AutoPilot also auto-generates a Candidate Definitions notebook. This notebook can be used to interactively step through the various steps taken by the Sagemaker Autopilot to arrive at the best candidate. This notebook can also be used to override various runtime parameters like parallelism, hardware used, algorithms explored, feature extraction scripts and more.\n",
    "\n",
    "The notebook can be downloaded from the following Amazon S3 location:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['AutoMLJobArtifacts']['CandidateDefinitionNotebookLocation']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration Notebook\n",
    "Sagemaker Autopilot also auto-generates a Data Exploration notebook, which can be downloaded from the following Amazon S3 location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)['AutoMLJobArtifacts']['DataExplorationNotebookLocation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
